I"©<p>Hello. today we will see another very basic and profound integral part of machine learning and statistics, Bayes filter. It mainly derived from bayes rule and itsâ€™ basic objective is to find out the likelihood/estimation of current state given all the actions and observations up to now. 
\(p(x_t|z_{1:t}, u_{1:t})\)
Usually, state estimation is called belief, so we introduce new term :
\(bel(x_t) = p(x_t|z_{1:t}, u_{1:t})\)</p>

<p>We will apply Bayes rule to simplify this term as it is almost impossible to directly obtain current state from actions and observations up to now.</p>
<ol>
  <li>Initially, i will separate \(z_t\) from \(z_{1:t}\) so that we can condition on it later.
    <p>
 $$bel(x_t) = p(x_t|z_t, z_{1:t-1}, u_{1:t}) $$
 </p>
  </li>
  <li>
    <p>Then, we will find probability of xt given all the actions up to now and all the observations exept the current observation given current observation using bayes rule. (I know it is little hard to stomach)</p>

    <p>
 $$bel(x_t) = p((x_t| z_{1:t-1}, u_{1:t}) | z_t) $$
 </p>
  </li>
  <li>
    <p><strong>After applying the Bayes theorem we will get the equation below. Here Î· denotes p(z). In Bayes theorem, as you may remember, we changed it so that  remaining part should sum up to one after multiplying with this Î· value.</strong></p>

    <p>
 $$bel(x_t) = p((x_t| z_{1:t-1}, u_{1:t}) | z_t) $$
 </p>
  </li>
</ol>

<p>
$$ P(A|B)= \frac{P(B|A)P(A)}{P(B)} $$
</p>
:ET